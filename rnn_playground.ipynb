{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, DelimitedFiles                                                       \n",
    "using LinearAlgebra, Random                                                      \n",
    "using Distributions                                                              \n",
    "using Flux: onehot, onecold, throttle, logitcrossentropy, chunk, batchseq\n",
    "using Flux.Optimise: update!       \n",
    "using Base.Iterators: partition\n",
    "using Zygote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 0:1\n",
    "batch_size = 10\n",
    "\n",
    "train_path = \"samples_N=2_h=1\"\n",
    "psi_path = \"psi_N=2_h=1\"\n",
    "\n",
    "data = Int.(readdlm(train_path))\n",
    "psi = readdlm(psi_path)[:,1]\n",
    "\n",
    "train_data = data[1:10000, :]\n",
    "test_data = data[10001:end, :]\n",
    "\n",
    "N = size(train_data,2)\n",
    "\n",
    "m = Chain(\n",
    "    GRU(length(labels), 100),\n",
    "    GRU(100, length(labels)),\n",
    "    softmax\n",
    ")\n",
    "m = f64(m)\n",
    "opt = ADAM(0.01)\n",
    "\n",
    "train_data = map(ch -> onehot(ch, labels), train_data)\n",
    "train_data = collect(partition(batchseq(chunk(train_data, batch_size)), N));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fidelity (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function probability(v)\n",
    "    # initialize the calculation with an all-zero configuration\n",
    "    init_config = zeros(1,size(v[1],2))\n",
    "    # onehot init_config\n",
    "    init_config = map(ch -> onehot(ch, labels), init_config)\n",
    "    init_config = batchseq(chunk(init_config, size(v[1],2)))\n",
    "\n",
    "    # concactenate init_config and v[1:end-1]\n",
    "    vp = vcat(init_config, v[1:end-1])\n",
    "\n",
    "    # apply model to vp\n",
    "    probs = m.(vp)\n",
    "\n",
    "    # multiply conditionals to get probability vector\n",
    "    probs = vcat(probs...)\n",
    "    v = vcat(v...)\n",
    "    probs = dot.(probs, v)\n",
    "    \n",
    "    probs[probs .== 0] .= 1\n",
    "    probs = prod(probs, dims=1)\n",
    "    \n",
    "    return probs\n",
    "end  \n",
    "\n",
    "function loss(v)\n",
    "    prob = probability(v)\n",
    "    log_prob = log.(prob)\n",
    "    return -sum(log_prob) / length(prob)\n",
    "end\n",
    "\n",
    "function generate_hilbert_space(;hot=false)\n",
    "    # TODO: currently not outputting correct format for hot=True\n",
    "    dim = [i for i in 0:2^N-1]\n",
    "    space = reshape(parse.(Int64, split(bitstring(dim[1])[end-N+1:end],\"\")), (N,))\n",
    "    for i in 2:length(dim)\n",
    "        tmp = reshape(parse.(Int64, split(bitstring(dim[i])[end-N+1:end],\"\")), (N,))\n",
    "        space = hcat(space, tmp)\n",
    "    end\n",
    "    \n",
    "    space = reshape(space, (length(dim),N))\n",
    "    \n",
    "    if hot\n",
    "        space = map(ch -> onehot(ch, labels), space)\n",
    "        space = collect(partition(batchseq(chunk(space', length(dim))), N))[1]\n",
    "    end\n",
    "    \n",
    "    return space\n",
    "end\n",
    "\n",
    "function fidelity(space, target)\n",
    "    return dot(target, sqrt.(probability(space)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "v = [0 0; 1 1]\n",
    "@show chunk(v',2)\n",
    "v = map(ch -> onehot(ch, labels), v)\n",
    "@show chunk(v', 2)\n",
    "@show collect(partition(batchseq(chunk(v', 2)), 2))\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: fix generate hilbert space function\n",
    "#space = generate_hilbert_space(hot=true)\n",
    "# generate space for N=2 manually for now\n",
    "space = [[1 1 0 0; 0 0 1 1], [1 0 1 0; 0 1 0 1]]\n",
    "ps = Flux.params(m)\n",
    "                                                                                 \n",
    "epochs = 1:100                                                                   \n",
    "num_batches = size(train_data,1)                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(train_data[1]) = 1.5534910535991213\n",
      "ep = 1\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "Mutating arrays is not supported",
     "output_type": "error",
     "traceback": [
      "Mutating arrays is not supported",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] (::Zygote.var\"#359#360\")(::Nothing) at /Users/isaacdevlugt/.julia/packages/Zygote/Xgcgs/src/lib/array.jl:61",
      " [3] (::Zygote.var\"#2234#back#361\"{Zygote.var\"#359#360\"})(::Nothing) at /Users/isaacdevlugt/.julia/packages/ZygoteRules/6nssF/src/adjoint.jl:49",
      " [4] materialize! at ./broadcast.jl:848 [inlined]",
      " [5] materialize! at ./broadcast.jl:845 [inlined]",
      " [6] materialize! at ./broadcast.jl:841 [inlined]",
      " [7] probability at ./In[9]:19 [inlined]",
      " [8] (::typeof(∂(probability)))(::Array{Float64,2}) at /Users/isaacdevlugt/.julia/packages/Zygote/Xgcgs/src/compiler/interface2.jl:0",
      " [9] loss at ./In[9]:26 [inlined]",
      " [10] (::typeof(∂(loss)))(::Float64) at /Users/isaacdevlugt/.julia/packages/Zygote/Xgcgs/src/compiler/interface2.jl:0",
      " [11] #17 at ./In[12]:8 [inlined]",
      " [12] (::typeof(∂(λ)))(::Float64) at /Users/isaacdevlugt/.julia/packages/Zygote/Xgcgs/src/compiler/interface2.jl:0",
      " [13] (::Zygote.var\"#54#55\"{Params,Zygote.Context,typeof(∂(λ))})(::Float64) at /Users/isaacdevlugt/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:177",
      " [14] gradient(::Function, ::Params) at /Users/isaacdevlugt/.julia/packages/Zygote/Xgcgs/src/compiler/interface.jl:54",
      " [15] top-level scope at In[12]:8",
      " [16] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "@show loss(train_data[1])\n",
    "\n",
    "for ep in epochs\n",
    "    @show ep\n",
    "    for b in 1:num_batches\n",
    "        batch = train_data[b]\n",
    "        Flux.reset!(m)\n",
    "        gs = Flux.gradient(() -> loss(batch), ps)\n",
    "        \n",
    "        update!(opt, ps, gs)\n",
    "    end\n",
    "\n",
    "    println(\"fidelity: \", fidelity(space, psi))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
